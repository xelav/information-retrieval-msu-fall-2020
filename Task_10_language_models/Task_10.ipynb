{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "4c718f4b7b81c0b2f2dc7e5cb725011a0cc68e54295894b90c03f879e3b46d73"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import numpy.ma as ma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ДЗ 10 от 19.10.20\n",
    "\n",
    "## Задание\n",
    "\n",
    "Реализовать языковую модель информационного поиска для поиска предложений в Википедии для $\\lambda_1 = 0.5$  и $\\lambda_2 = 0.9$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загружаем лемматизированные тексты из предыдущего задания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'Пейзаж с выжженной равниной увековечил образ вечного города.',\n",
    "    'Будущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.',\n",
    "    'Трезубец на жёлто-синем фоне — это флаг Барбадоса.'\n",
    "]\n",
    "\n",
    "with open('../Task_4/lemmatized.pkl', 'rb') as output_file:\n",
    "    docs, original_sentences, queries_processed = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убираем односимвольные токены и документы без токенов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "docs = [[t for t in tokens if len(t)>1] for tokens in docs]\n",
    "\n",
    "original_sentences = [sent for tokens, sent in zip(docs, original_sentences) if len(tokens)>0]\n",
    "docs = [tokens for tokens in docs if len(tokens)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Векторизуем документы и запросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(docs, vocab=None):\n",
    "    '''\n",
    "    docs - list of lists of tokens\n",
    "    vocab - set of tokens\n",
    "    Returns count array with shape (N x V), where N - number of documents and V - size of vocab\n",
    "    '''\n",
    "    if vocab is None:\n",
    "        vocab = set([token for sentence in docs for token in sentence if len(token)>0])\n",
    "    vectorized = np.zeros((len(docs),len(vocab)))\n",
    "\n",
    "    token_ind_dict = {tok: ind for ind, tok in dict(enumerate(vocab)).items()}\n",
    "\n",
    "    for doc_ind, doc in enumerate(docs):\n",
    "        for token in doc:\n",
    "            try:\n",
    "                token_id = token_ind_dict[token]\n",
    "                vectorized[doc_ind][token_id] += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return vectorized, token_ind_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([token for sentence in docs for token in sentence if len(token)>1])\n",
    "doc_vec, token_ind_dict = vectorize(docs, vocab)\n",
    "queries_vec, _ = vectorize(queries_processed, vocab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция вычисления вероятностей для одного запроса:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lm_probs(query_vec, doc_vec, lmbd):\n",
    "\n",
    "    query_terms = np.where(query_vec)[0]\n",
    "    corpus_freqs = doc_vec.sum(axis=0)\n",
    "    corpus_size = corpus_freqs.sum()\n",
    "    doc_sizes = doc_vec.sum(axis=1)\n",
    "\n",
    "    global_probs = corpus_freqs[query_terms] / corpus_size\n",
    "    local_probs = (doc_vec[:,query_terms].T / doc_sizes).T\n",
    "\n",
    "    doc_probs = np.prod(global_probs * lmbd + local_probs * (1-lmbd), axis=1)\n",
    "\n",
    "    return doc_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты для случая $\\lambda_1 = 0.5$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query:\nПейзаж с выжженной равниной увековечил образ вечного города.\n\nResults:\n  Weight     | Sentence\n(2.0586e-04)  рим стали часто называть вечным лат\n(3.6289e-05)  также рим называют городом на семи холмах\n(3.6289e-05)  roma ˈroːma  столица и крупнейший город италии\n------\n\nQuery:\nБудущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.\n\nResults:\n  Weight     | Sentence\n(1.1438e-10)  биологическое оружие\n(1.7276e-11)  в 1879 году он был избран губернатором кентукки от демократической партии\n(6.2974e-12)  luke pryor blackburn 16 июня 1816  14 сентября 1887  американский врач и политик губернатор штата кентукки в 18791883 годах\n------\n\nQuery:\nТрезубец на жёлто-синем фоне — это флаг Барбадоса.\n\nResults:\n  Weight     | Sentence\n(9.3245e-11)  флаг барбадоса  официальный символ государства барбадос\n(3.3265e-13)  посейдон со своей женой богиней амфитритой и сыном тритоном обитают в роскошном дворце на дне моря в окружении нереид гиппокампов и других обитателей моря мчится по морю на колеснице запряжённой гиппокампусами с трезубцем которым вызывал бури разбивал скалы ударял по земле что приводило к образованию родников с пресной или морской водой\n(6.1397e-14)  расположен на реке тибр\n------\n\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "\n",
    "    lm_probs = get_lm_probs(queries_vec[i], doc_vec, lmbd=0.5)\n",
    "\n",
    "    print(f\"Query:\\n{query}\\n\")\n",
    "    print(\"Results:\\n  Weight     | Sentence\")\n",
    "\n",
    "    for ind in lm_probs.argsort()[:-4:-1]:\n",
    "        print(f\"({lm_probs[ind]:.4e})  {original_sentences[ind]}\")\n",
    "        # print(f\"With weight {query_results[ind,i]:.6f}\")\n",
    "    print(\"------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Результаты для случая $\\lambda_2 = 0.9$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Query:\nПейзаж с выжженной равниной увековечил образ вечного города.\n\nResults:\n  Weight    | Sentence\n(7.7582e-05)  рим стали часто называть вечным лат\n(1.6538e-05)  также рим называют городом на семи холмах\n(1.6538e-05)  roma ˈroːma  столица и крупнейший город италии\n------\n\nQuery:\nБудущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.\n\nResults:\n  Weight    | Sentence\n(3.3223e-11)  биологическое оружие\n(6.8081e-12)  в 1879 году он был избран губернатором кентукки от демократической партии\n(3.9720e-12)  его обвинили в заговоре с целью убийства и в нарушении нейтралитета канады но освободили под залог в 8000 долларов\n------\n\nQuery:\nТрезубец на жёлто-синем фоне — это флаг Барбадоса.\n\nResults:\n  Weight    | Sentence\n(2.3839e-11)  флаг барбадоса  официальный символ государства барбадос\n(2.9532e-13)  посейдон со своей женой богиней амфитритой и сыном тритоном обитают в роскошном дворце на дне моря в окружении нереид гиппокампов и других обитателей моря мчится по морю на колеснице запряжённой гиппокампусами с трезубцем которым вызывал бури разбивал скалы ударял по земле что приводило к образованию родников с пресной или морской водой\n(1.8267e-13)  расположен на реке тибр\n------\n\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "\n",
    "    lm_probs = get_lm_probs(queries_vec[i], doc_vec, lmbd=0.9)\n",
    "\n",
    "    print(f\"Query:\\n{query}\\n\")\n",
    "    print(\"Results:\\n  Weight    | Sentence\")\n",
    "\n",
    "    for ind in lm_probs.argsort()[:-4:-1]:\n",
    "        print(f\"({lm_probs[ind]:.4e})  {original_sentences[ind]}\")\n",
    "        # print(f\"With weight {query_results[ind,i]:.6f}\")\n",
    "    print(\"------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для двух случаев абсолютные величины вероятностей меняются значительно, однако порядок для топ-3 документов сохраняется.\n",
    "\n",
    "Для данного случая, результаты по запросам выглядят заметно более осмысленными, если сравнивать с результатами TF-iDF модели"
   ]
  }
 ]
}