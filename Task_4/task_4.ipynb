{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wikipedia\n",
    "import re\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "\n",
    "wikipedia.set_lang('ru')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_names = ['Трезубец_Посейдона', 'Флаг Барбадоса', 'Биологическое_оружие',\n",
    "'Блэкберн,_Люк_Прайор', 'Рим', 'Аппиева_дорога_при_закате_солнца']\n",
    "\n",
    "wikipedia_pages = [wikipedia.page(page_name) for page_name in page_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'Пейзаж с выжженной равниной увековечил образ вечного города.',\n",
    "    'Будущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.',\n",
    "    'Трезубец на жёлто-синем фоне — это флаг Барбадоса.'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Installing mystem to C:\\Users\\admin/.local/bin\\mystem.exe from http://download.cdn.yandex.net/mystem/mystem-3.1-win-64bit.zip\n",
      "100%|██████████████████████████████████████████| 44/44 [00:36<00:00,  1.21it/s]\n",
      "100%|████████████████████████████████████████████| 2/2 [00:01<00:00,  1.21it/s]\n",
      "100%|██████████████████████████████████████████| 11/11 [00:08<00:00,  1.24it/s]\n",
      "100%|██████████████████████████████████████████| 36/36 [00:36<00:00,  1.02s/it]\n",
      "100%|██████████████████████████████████████████| 22/22 [00:23<00:00,  1.06s/it]\n",
      "100%|██████████████████████████████████████████| 31/31 [00:28<00:00,  1.10it/s]\n"
     ]
    }
   ],
   "source": [
    "docs = []\n",
    "original_sentences = []\n",
    "m = Mystem()\n",
    "for page in wikipedia_pages:\n",
    "    s = re.sub('\\s', ' ', page.content) # remove newlines and tabs\n",
    "    s = re.sub('\\=\\= Примечания[\\w\\s\\=]*', '', s) # remove all text after 'Примечания'\n",
    "    s = re.sub(r'\\=\\=.*\\=\\=', ' ', s) # remove headers\n",
    "    s = re.sub(r'[^\\w \\.]', '', s.lower()) # remove non-letter symbols\n",
    "    s = [doc.strip() for doc in s.split('.')]\n",
    "    if\n",
    "    original_sentences += s\n",
    "    with Pool(4) as p:\n",
    "        lemmitized = list(tqdm(p.imap(m.lemmatize, s), total=len(s)))\n",
    "    # lemmitized = [m.lemmatize(doc) for doc in s]\n",
    "    docs += [[lemma for lemma in doc if lemma.isalpha() or lemma.isdigit()] for doc in lemmitized]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████| 3/3 [00:05<00:00,  1.98s/it]\n"
     ]
    }
   ],
   "source": [
    "queries_processed = []\n",
    "for query in tqdm(queries):\n",
    "    s = m.lemmatize(query.lower())\n",
    "    s = [lemma for lemma in s if lemma.isalpha() or lemma.isdigit()]\n",
    "    queries_processed.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATA = False\n",
    "if SAVE_DATA:\n",
    "    with open('lemmatized.pkl', 'wb') as output_file:\n",
    "        pickle.dump((docs, original_sentences, queries_processed), output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('lemmatized.pkl', 'rb') as output_file:\n",
    "    docs, original_sentences, queries_processed = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-iDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize(docs, vocab=None):\n",
    "    '''\n",
    "    docs - list of lists of tokens\n",
    "    vocab - set of tokens\n",
    "    Returns count array with shape (N x V), where N - number of documents and V - size of vocab\n",
    "    '''\n",
    "    if vocab is None:\n",
    "        vocab = set([token for sentence in docs for token in sentence if len(token)>1])\n",
    "    vectorized = np.zeros((len(docs),len(vocab)))\n",
    "\n",
    "    token_ind_dict = {tok: ind for ind, tok in dict(enumerate(vocab)).items()}\n",
    "\n",
    "    for doc_ind, doc in enumerate(docs):\n",
    "        for token in doc:\n",
    "            try:\n",
    "                token_id = token_ind_dict[token]\n",
    "                vectorized[doc_ind][token_id] += 1\n",
    "            except KeyError:\n",
    "                pass\n",
    "    return vectorized\n",
    "\n",
    "def get_tf(matrix):\n",
    "    return matrix\n",
    "\n",
    "def get_tf_norm(matrix):\n",
    "    return np.nan_to_num(matrix / matrix.sum(axis=0))\n",
    "\n",
    "def get_tf_max_norm(matrix, alpha=0.4):\n",
    "    tf =  alpha + (1-alpha) * np.nan_to_num(matrix / matrix.max(axis=1)[:,None])\n",
    "    tf[tf == alpha] = 0\n",
    "    return tf\n",
    "\n",
    "def get_idf(matrix, smoothing=3):\n",
    "    return matrix.shape[0] / ((matrix > 0).sum(axis=0) + 1)\n",
    "    # return np.nan_to_num(matrix.shape[0] / ((matrix > 0).sum(axis=0)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove short tokens and sentences without tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# docs = [tokens for tokens, sent in zip(docs, original_sentences) if len(sent)>5]\n",
    "# original_sentences = [sent for sent in original_sentences if len(sent)>5]\n",
    "\n",
    "# original_sentences = [sent for tokens, sent in zip(docs, original_sentences) if len(tokens)>0]\n",
    "# docs = [tokens for tokens in docs if len(tokens)>0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No TF normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set([token for sentence in docs for token in sentence if len(token)>1])\n",
    "doc_vec = vectorize(docs, vocab)\n",
    "doc_tf = get_tf(doc_vec)\n",
    "doc_idf = get_idf(doc_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries_vec = vectorize(queries_processed, vocab)\n",
    "queries_tf = get_tf(queries_vec)\n",
    "# queries_idf = get_idf(queries_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101,  55,  44], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = doc_tf * doc_idf\n",
    "X = normalize(X, axis=1)\n",
    "queries_tfidf = queries_tf * doc_idf\n",
    "query_results = cosine_similarity(X, queries_tfidf)\n",
    "query_results.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Пейзаж с выжженной равниной увековечил образ вечного города.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.550276)  рим стали часто называть вечным лат\n",
      "(0.079148)  также рим называют городом на семи холмах\n",
      "(0.055470)  рим  один из старейших городов мира древняя столица римской империи\n",
      "------\n",
      "\n",
      "Query:\n",
      "Будущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.309441)  биологическое оружие\n",
      "(0.256880)  его обвинили в заговоре с целью убийства и в нарушении нейтралитета канады но освободили под залог в 8000 долларов\n",
      "(0.144803)  в 1879 году он был избран губернатором кентукки от демократической партии\n",
      "------\n",
      "\n",
      "Query:\n",
      "Трезубец на жёлто-синем фоне — это флаг Барбадоса.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.594446)  флаг барбадоса  официальный символ государства барбадос\n",
      "(0.101780)  посейдон со своей женой богиней амфитритой и сыном тритоном обитают в роскошном дворце на дне моря в окружении нереид гиппокампов и других обитателей моря мчится по морю на колеснице запряжённой гиппокампусами с трезубцем которым вызывал бури разбивал скалы ударял по земле что приводило к образованию родников с пресной или морской водой\n",
      "(0.035525)  блэкберн якобы заявил хьямсу что это убьет как самого президента так и всех других обитателей белого дома\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "    print(f\"Query:\\n{query}\\n\")\n",
    "    print(\"Results:\\n  Weight  | Sentence\")\n",
    "    for ind in query_results[:,i].argsort()[:-4:-1]:\n",
    "        print(f\"({query_results[ind,i]:.6f})  {original_sentences[ind]}\")\n",
    "        # print(f\"With weight {query_results[ind,i]:.6f}\")\n",
    "    print(\"------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Резульаты похожи на то, что выдает реализация TF-iDF из пакета sklearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max TF normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python36\\lib\\site-packages\\ipykernel_launcher.py:29: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "alpha = 0.4\n",
    "\n",
    "doc_tf_2 = get_tf_max_norm(doc_vec, alpha=alpha)\n",
    "queries_tf_2 = get_tf_max_norm(queries_vec, alpha=alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([101,  55,  44], dtype=int64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_2 = doc_tf_2 * doc_idf\n",
    "# X_2 =  normalize(X_2)\n",
    "queries_tfidf_2 = queries_tf_2 * doc_idf\n",
    "# queries_tfidf_2 = normalize(queries_tfidf_2, axis=1)\n",
    "query_results_2 = cosine_similarity(X_2, queries_tfidf_2)\n",
    "query_results_2.argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:\n",
      "Пейзаж с выжженной равниной увековечил образ вечного города.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.550276)  рим стали часто называть вечным лат\n",
      "(0.079148)  также рим называют городом на семи холмах\n",
      "(0.055470)  рим  один из старейших городов мира древняя столица римской империи\n",
      "------\n",
      "\n",
      "Query:\n",
      "Будущего губернатора Кентукки обвиняли в подготовке применения биологического оружия.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.309441)  биологическое оружие\n",
      "(0.256880)  его обвинили в заговоре с целью убийства и в нарушении нейтралитета канады но освободили под залог в 8000 долларов\n",
      "(0.144803)  в 1879 году он был избран губернатором кентукки от демократической партии\n",
      "------\n",
      "\n",
      "Query:\n",
      "Трезубец на жёлто-синем фоне — это флаг Барбадоса.\n",
      "\n",
      "Results:\n",
      "  Weight  | Sentence\n",
      "(0.553782)  флаг барбадоса  официальный символ государства барбадос\n",
      "(0.105098)  посейдон со своей женой богиней амфитритой и сыном тритоном обитают в роскошном дворце на дне моря в окружении нереид гиппокампов и других обитателей моря мчится по морю на колеснице запряжённой гиппокампусами с трезубцем которым вызывал бури разбивал скалы ударял по земле что приводило к образованию родников с пресной или морской водой\n",
      "(0.035525)  блэкберн якобы заявил хьямсу что это убьет как самого президента так и всех других обитателей белого дома\n",
      "------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i, query in enumerate(queries):\n",
    "    print(f\"Query:\\n{query}\\n\")\n",
    "    print(\"Results:\\n  Weight  | Sentence\")\n",
    "    for ind in query_results_2[:,i].argsort()[:-4:-1]:\n",
    "        print(f\"({query_results_2[ind,i]:.6f})  {original_sentences[ind]}\")\n",
    "        # print(f\"With weight {query_results[ind,i]:.6f}\")\n",
    "    print(\"------\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
