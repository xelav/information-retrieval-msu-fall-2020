{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit (conda)",
   "metadata": {
    "interpreter": {
     "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.cElementTree as ET\n",
    "from pymystem3 import Mystem\n",
    "from tqdm import tqdm\n",
    "from multiprocessing import Pool\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "russian_stopwords = stopwords.words(\"russian\")\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xml(filename):\n",
    "\n",
    "    tree = ET.ElementTree(file=filename)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    sentences = []\n",
    "    labels = []\n",
    "\n",
    "    for sentence in list(root.iter('document'))[0].iter('sentence'):\n",
    "        speech = sentence.findall('speech')[0].text.strip()\n",
    "        evaluation = sentence.findall('evaluation')[0].text.strip()\n",
    "\n",
    "        if evaluation in {'+', '0', '-'}:\n",
    "            sentences.append(speech)\n",
    "            labels.append(evaluation)\n",
    "    return sentences, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sentences, train_labels = preprocess_xml('data/train/news_eval_train.xml')\n",
    "\n",
    "test_sentence, test_labels = preprocess_xml('data/test/news_eval_test.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_corups(corpus, pool_size=4):\n",
    "    \"\"\"\n",
    "    corpus - list of sentences\n",
    "    \"\"\"\n",
    "    m = Mystem()\n",
    "    with Pool(pool_size) as p:\n",
    "        lemmitized = list(tqdm(p.imap(m.lemmatize, corpus), total=len(corpus)))\n",
    "        \n",
    "    # docs = [[lemma for lemma in doc if (lemma not in russian_stopwords) and (lemma.isalpha() or lemma.isdigit())] for doc in lemmitized]\n",
    "    docs = [[lemma for lemma in doc if lemma.isalpha() or lemma.isdigit()] for doc in lemmitized]\n",
    "    return docs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 3893/3893 [23:12<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "train_sentences_preprocessed = preprocess_corups(train_sentences, pool_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 4573/4573 [10:26:50<00:00,  8.22s/it]\n"
     ]
    }
   ],
   "source": [
    "test_sentences_preprocessed = preprocess_corups(test_sentence, pool_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_DATA = False\n",
    "if SAVE_DATA:\n",
    "    with open('preprocessed_data.pkl', 'wb') as output_file:\n",
    "        pickle.dump((\n",
    "            train_sentences_preprocessed, train_labels,\n",
    "            test_sentences_preprocessed, test_labels),\n",
    "        output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('preprocessed_data.pkl', 'rb') as output_file:\n",
    "    train_sentences_preprocessed, train_labels,\\\n",
    "    test_sentences_preprocessed, test_labels = pickle.load(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_data(vectorizer_type='TF-iDF'):\n",
    "\n",
    "    if vectorizer_type == 'TF-iDF':\n",
    "        vectorizer = TfidfVectorizer(\n",
    "            preprocessor=lambda x: x, tokenizer=lambda x: x,\n",
    "            ngram_range=(1,2)\n",
    "        )\n",
    "    elif vectorizer_type == 'Count':\n",
    "        vectorizer = CountVectorizer(\n",
    "            preprocessor=lambda x: x, tokenizer=lambda x: x,\n",
    "            binary=False, ngram_range=(1,2)\n",
    "        )\n",
    "    elif vectorizer_type == 'Binary':\n",
    "        vectorizer = CountVectorizer(\n",
    "            preprocessor=lambda x: x, tokenizer=lambda x: x,\n",
    "            binary=True, ngram_range=(1,2)\n",
    "        )\n",
    "    else:\n",
    "        raise ValueError(f\"Wrong vectorizer_type value: {vectorizer_type}\")\n",
    "\n",
    "    X_train = vectorizer.fit_transform(train_sentences_preprocessed)\n",
    "    X_test = vectorizer.transform(test_sentences_preprocessed)\n",
    "    return X_train, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    model_mlb = OneVsRestClassifier(model)\n",
    "    model_mlb.fit(X_train, y_train)\n",
    "    prediction = model_mlb.predict(X_test)\n",
    "    train_prediction = model_mlb.predict(X_train)\n",
    "\n",
    "    print(\"Train results\")\n",
    "    print(f\"Accuracy: {accuracy_score(train_prediction, y_train):.4f}  F1-micro: {f1_score(train_prediction, y_train, average='micro'):.4f}   F1-macro: {f1_score(train_prediction, y_train, average='macro'):.4f}\")\n",
    "\n",
    "    print(\"Test results\")\n",
    "    print(f\"Accuracy: {accuracy_score(prediction, y_test):.4f}  F1-micro: {f1_score(prediction, y_test, average='macro'):.4f}   F1-micro: {f1_score(prediction, y_test, average='macro'):.4f}\")"
   ]
  },
  {
   "source": [
    "## TF-iDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = vectorize_data('TF-iDF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.9699  F1-micro: 0.9837   F1-macro: 0.9797\nTest results\nAccuracy: 0.4787  F1-micro: 0.4950   F1-micro: 0.4950\n"
     ]
    }
   ],
   "source": [
    "test_model(LinearSVC(C=1, loss='hinge'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.9938  F1-micro: 0.9969   F1-macro: 0.9960\nTest results\nAccuracy: 0.0013  F1-micro: 0.0021   F1-micro: 0.0021\n"
     ]
    }
   ],
   "source": [
    "test_model(SVC(kernel='poly'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.9877  F1-micro: 0.9938   F1-macro: 0.9921\nTest results\nAccuracy: 0.3335  F1-micro: 0.3456   F1-micro: 0.3456\n"
     ]
    }
   ],
   "source": [
    "test_model(SVC(kernel='rbf'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.8592  F1-micro: 0.9201   F1-macro: 0.8899\nTest results\nAccuracy: 0.4638  F1-micro: 0.4777   F1-micro: 0.4777\n"
     ]
    }
   ],
   "source": [
    "test_model(SVC(kernel='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.9987  F1-micro: 0.9992   F1-macro: 0.9991\nTest results\nAccuracy: 0.2987  F1-micro: 0.3368   F1-micro: 0.3368\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "test_model(RandomForestClassifier(n_estimators=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.6047  F1-micro: 0.7499   F1-macro: 0.5823\nTest results\nAccuracy: 0.3523  F1-micro: 0.3652   F1-micro: 0.3652\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "test_model(LogisticRegression(C=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.9959  F1-micro: 0.9979   F1-macro: 0.9974\nTest results\nAccuracy: 0.4811  F1-micro: 0.5035   F1-micro: 0.5035\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "clf = BaggingClassifier(base_estimator=LinearSVC(C=10),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.8341  F1-micro: 0.8981   F1-macro: 0.8818\nTest results\nAccuracy: 0.4465  F1-micro: 0.5152   F1-micro: 0.5152\n"
     ]
    }
   ],
   "source": [
    "import lightgbm as lgb\n",
    "\n",
    "lgb_params = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "test_model(lgb.LGBMClassifier(**lgb_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Train results\nAccuracy: 0.5289  F1-micro: 0.6879   F1-macro: 0.4738\nTest results\nAccuracy: 0.3136  F1-micro: 0.3248   F1-micro: 0.3248\n"
     ]
    }
   ],
   "source": [
    "clf = BaggingClassifier(base_estimator=LogisticRegression(),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)"
   ]
  },
  {
   "source": [
    "## Проверка, совпадают ли train и test распределения\n",
    "\n",
    "Можно попытаться объяснить большую разницу в результатах для train и test наборов различием в их распределениях.\n",
    "\n",
    "Для этого мы попытаемся обучить модель отличать тестовую выборку от тренировочной. В идеале, если обе выборки имеют одно и то же распределение, то модель не сможет обучиться."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Частотные вектора"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "LinearSVC\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.4739  F1-micro: 0.5344   F1-micro: 0.5344\n",
      "\n",
      "\n",
      "SVC-poly\n",
      "Train results\n",
      "Accuracy: 0.4696  F1-micro: 0.6390   F1-macro: 0.5953\n",
      "Test results\n",
      "Accuracy: 0.0575  F1-micro: 0.1391   F1-micro: 0.1391\n",
      "\n",
      "\n",
      "SVC-rbf\n",
      "Train results\n",
      "Accuracy: 0.8184  F1-micro: 0.8962   F1-macro: 0.8570\n",
      "Test results\n",
      "Accuracy: 0.3477  F1-micro: 0.3694   F1-micro: 0.3694\n",
      "\n",
      "\n",
      "SVC-sigmoid\n",
      "Train results\n",
      "Accuracy: 0.5679  F1-micro: 0.6993   F1-macro: 0.6248\n",
      "Test results\n",
      "Accuracy: 0.3536  F1-micro: 0.3917   F1-micro: 0.3917\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.2305  F1-micro: 0.2583   F1-micro: 0.2583\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.4605  F1-micro: 0.5063   F1-micro: 0.5063\n",
      "\n",
      "\n",
      "LinearSVM-bagging\n",
      "Train results\n",
      "Accuracy: 0.9920  F1-micro: 0.9957   F1-macro: 0.9948\n",
      "Test results\n",
      "Accuracy: 0.4520  F1-micro: 0.5076   F1-micro: 0.5076\n",
      "\n",
      "\n",
      "LogisticRegression-bagging\n",
      "Train results\n",
      "Accuracy: 0.9584  F1-micro: 0.9776   F1-macro: 0.9720\n",
      "Test results\n",
      "Accuracy: 0.4238  F1-micro: 0.4684   F1-micro: 0.4684\n",
      "\n",
      "\\LGBM\n",
      "Train results\n",
      "Accuracy: 0.7449  F1-micro: 0.8363   F1-macro: 0.8089\n",
      "Test results\n",
      "Accuracy: 0.4295  F1-micro: 0.4825   F1-micro: 0.4825\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = vectorize_data('Count')\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(\"\\n\\nLinearSVC\")\n",
    "test_model(LinearSVC(C=1, loss='hinge'))\n",
    "\n",
    "print(\"\\n\\nSVC-poly\")\n",
    "test_model(SVC(kernel='poly'))\n",
    "print(\"\\n\\nSVC-rbf\")\n",
    "test_model(SVC(kernel='rbf')) \n",
    "print(\"\\n\\nSVC-sigmoid\") \n",
    "test_model(SVC(kernel='sigmoid'))\n",
    "\n",
    "print(\"\\n\\nRandomForest\")\n",
    "test_model(RandomForestClassifier(n_estimators=1000))\n",
    "\n",
    "print(\"\\n\\nLogisticRegression\")\n",
    "test_model(LogisticRegression(C=1))\n",
    "\n",
    "print(\"\\n\\nLinearSVM-bagging\")\n",
    "clf = BaggingClassifier(base_estimator=LinearSVC(C=10),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)\n",
    "\n",
    "print(\"\\n\\nLogisticRegression-bagging\")\n",
    "clf = BaggingClassifier(base_estimator=LogisticRegression(),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)\n",
    "\n",
    "print(\"\\nLGBM\")\n",
    "lgb_params = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "test_model(lgb.LGBMClassifier(**lgb_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "LinearSVC\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.4763  F1-micro: 0.5333   F1-micro: 0.5333\n",
      "\n",
      "\n",
      "SVC-poly\n",
      "Train results\n",
      "Accuracy: 0.5936  F1-micro: 0.7450   F1-macro: 0.6843\n",
      "Test results\n",
      "Accuracy: 0.0037  F1-micro: 0.0072   F1-micro: 0.0072\n",
      "\n",
      "\n",
      "SVC-rbf\n",
      "Train results\n",
      "Accuracy: 0.8695  F1-micro: 0.9277   F1-macro: 0.9024\n",
      "Test results\n",
      "Accuracy: 0.3260  F1-micro: 0.3613   F1-micro: 0.3613\n",
      "\n",
      "\n",
      "SVC-sigmoid\n",
      "Train results\n",
      "Accuracy: 0.6807  F1-micro: 0.7949   F1-macro: 0.7027\n",
      "Test results\n",
      "Accuracy: 0.3842  F1-micro: 0.4078   F1-micro: 0.4078\n",
      "\n",
      "\n",
      "RandomForest\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.2233  F1-micro: 0.2525   F1-micro: 0.2525\n",
      "\n",
      "\n",
      "LogisticRegression\n",
      "Train results\n",
      "Accuracy: 0.9985  F1-micro: 0.9992   F1-macro: 0.9991\n",
      "Test results\n",
      "Accuracy: 0.4581  F1-micro: 0.5080   F1-micro: 0.5080\n",
      "\n",
      "\n",
      "LinearSVM-bagging\n",
      "Train results\n",
      "Accuracy: 0.9938  F1-micro: 0.9969   F1-macro: 0.9961\n",
      "Test results\n",
      "Accuracy: 0.4522  F1-micro: 0.5097   F1-micro: 0.5097\n",
      "\n",
      "\n",
      "LogisticRegression-bagging\n",
      "Train results\n",
      "Accuracy: 0.9612  F1-micro: 0.9793   F1-macro: 0.9736\n",
      "Test results\n",
      "Accuracy: 0.4207  F1-micro: 0.4653   F1-micro: 0.4653\n",
      "\n",
      "\\LGBM\n",
      "Train results\n",
      "Accuracy: 0.7372  F1-micro: 0.8280   F1-macro: 0.7978\n",
      "Test results\n",
      "Accuracy: 0.4317  F1-micro: 0.4787   F1-micro: 0.4787\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = vectorize_data('Binary')\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "print(\"\\n\\nLinearSVC\")\n",
    "test_model(LinearSVC(C=1, loss='hinge'))\n",
    "\n",
    "print(\"\\n\\nSVC-poly\")\n",
    "test_model(SVC(kernel='poly'))\n",
    "print(\"\\n\\nSVC-rbf\")\n",
    "test_model(SVC(kernel='rbf')) \n",
    "print(\"\\n\\nSVC-sigmoid\") \n",
    "test_model(SVC(kernel='sigmoid'))\n",
    "\n",
    "print(\"\\n\\nRandomForest\")\n",
    "test_model(RandomForestClassifier(n_estimators=1000))\n",
    "\n",
    "print(\"\\n\\nLogisticRegression\")\n",
    "test_model(LogisticRegression(C=1))\n",
    "\n",
    "print(\"\\n\\nLinearSVM-bagging\")\n",
    "clf = BaggingClassifier(base_estimator=LinearSVC(C=10),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)\n",
    "\n",
    "print(\"\\n\\nLogisticRegression-bagging\")\n",
    "clf = BaggingClassifier(base_estimator=LogisticRegression(),\n",
    "                        n_estimators=25, random_state=0,\n",
    "                        max_features=0.9)\n",
    "test_model(clf)\n",
    "\n",
    "print(\"\\n\\LGBM\")\n",
    "lgb_params = {\n",
    "    'max_depth': 3,\n",
    "    'learning_rate': 0.1,\n",
    "    'n_estimators': 1000\n",
    "}\n",
    "\n",
    "test_model(lgb.LGBMClassifier(**lgb_params))"
   ]
  },
  {
   "source": [
    "## Булевские вектора"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Результаты\n",
    "\n",
    "Результаты приведены в следующей таблице:\n",
    "\n",
    "|                               | TF-iDF | Count  | Binary |\n",
    "|-------------------------------|--------|--------|--------|\n",
    "| SVM-linear                    | 0.4787 | 0.4739 | 0.4763 |\n",
    "| SVM-poly                      | 0.0013 | 0.0575 | 0.0037 |\n",
    "| SVM-rbf                       | 0.3335 | 0.3477 | 0.3260 |\n",
    "| SVM-sigmoid                   | 0.4638 | 0.3536 | 0.3842 |\n",
    "| RandomForest                  | 0.2987 | 0.2305 | 0.2233 |\n",
    "| LogisticRegression            | 0.3523 | 0.4605 | 0.4581 |\n",
    "| SVM-linear-bagging-25         | 0.4811 | 0.4520 | 0.4522 |\n",
    "| LogisticRegression-bagging-25 | 0.3136 | 0.4238 | 0.4207 |\n",
    "| LGBM                          | 0.4465 | 0.4295 | 0.4317 |\n",
    "\n",
    "Ни один из классификаторов не побил бейзлайн. Лучше всего себя показал линейный SVM.\n",
    "\n",
    "Большинство модели получили на тренировочной выборке точность, очень близкую к 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### TF-iDF"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 95% confidience interval: (0.7649 0.8486)\nAccuracy score with constant predictor: 0.5402\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as st\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "import scipy.sparse as sp\n",
    "\n",
    "X_train, X_test = vectorize_data(vectorizer_type='TF-iDF')\n",
    "\n",
    "X_full = sp.vstack([X_train, X_test], format='csr')\n",
    "x_is_train = np.hstack([np.ones(X_train.shape[0]), np.zeros(X_test.shape[0])])\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "cross_val_resuls = cross_validate(model, X_full, x_is_train, cv=5, scoring=['accuracy'])\n",
    "\n",
    "data = cross_val_resuls['test_accuracy']\n",
    "\n",
    "interval = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) \n",
    "print(f\"Accuracy 95% confidience interval: ({interval[0]:.4f} {interval[1]:.4f})\")\n",
    "\n",
    "print(f\"Accuracy score with constant predictor: {accuracy_score(x_is_train, np.zeros_like(x_is_train)):.4f}\")"
   ]
  },
  {
   "source": [
    "### Частотные вектора"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 95% confidience interval: (0.6823 0.7590)\nAccuracy score with constant predictor: 0.5402\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = vectorize_data(vectorizer_type='Count')\n",
    "\n",
    "X_full = sp.vstack([X_train, X_test], format='csr')\n",
    "x_is_train = np.hstack([np.ones(X_train.shape[0]), np.zeros(X_test.shape[0])])\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "cross_val_resuls = cross_validate(model, X_full, x_is_train, cv=5, scoring=['accuracy'])\n",
    "\n",
    "data = cross_val_resuls['test_accuracy']\n",
    "\n",
    "interval = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) \n",
    "print(f\"Accuracy 95% confidience interval: ({interval[0]:.4f} {interval[1]:.4f})\")\n",
    "\n",
    "print(f\"Accuracy score with constant predictor: {accuracy_score(x_is_train, np.zeros_like(x_is_train)):.4f}\")"
   ]
  },
  {
   "source": [
    "### Булевские вектора"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy 95% confidience interval: (0.6859 0.7665)\nAccuracy score with constant predictor: 0.5402\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test = vectorize_data(vectorizer_type='Binary')\n",
    "\n",
    "X_full = sp.vstack([X_train, X_test], format='csr')\n",
    "x_is_train = np.hstack([np.ones(X_train.shape[0]), np.zeros(X_test.shape[0])])\n",
    "\n",
    "model = LinearSVC()\n",
    "\n",
    "cross_val_resuls = cross_validate(model, X_full, x_is_train, cv=5, scoring=['accuracy'])\n",
    "\n",
    "data = cross_val_resuls['test_accuracy']\n",
    "\n",
    "interval = st.t.interval(alpha=0.95, df=len(data)-1, loc=np.mean(data), scale=st.sem(data)) \n",
    "print(f\"Accuracy 95% confidience interval: ({interval[0]:.4f} {interval[1]:.4f})\")\n",
    "\n",
    "print(f\"Accuracy score with constant predictor: {accuracy_score(x_is_train, np.zeros_like(x_is_train)):.4f}\")"
   ]
  },
  {
   "source": [
    "Линейный SVM смог добиться точности значительно лучше, чем константная модель. Это указывает на то, что train и test наборы значительно отличаются друг от друга."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}